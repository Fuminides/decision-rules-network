{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44bab5d-a11d-4003-96ff-4f71c083fef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from datasets.dataset import transform_dataset, kfold_dataset\n",
    "from DRNet import train, DRNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec2653f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_NIPS_results():\n",
    "    return pd.read_csv('NIPS_crips_additive_rules_0999_8_1.csv', index_col=0, sep=';')\n",
    "\n",
    "\n",
    "def good_NIPS_datasets():\n",
    "    df = load_NIPS_results()\n",
    "\n",
    "    return list(df[df['Accuracy'] == df['Accuracy']].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f49dd5dd-aca4-46a7-8bbe-781f1a057ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read datasets\n",
    "name = 'iris'\n",
    "X, Y, X_headers, Y_headers = transform_dataset(name, method='onehot-compare', negations=False, labels='binary')\n",
    "datasets = kfold_dataset(X, Y, shuffle=1)\n",
    "X_train, X_test, Y_train, Y_test = datasets[0]\n",
    "\n",
    "train_set = torch.utils.data.TensorDataset(torch.Tensor(X_train.to_numpy()), torch.Tensor(Y_train))\n",
    "test_set = torch.utils.data.TensorDataset(torch.Tensor(X_test.to_numpy()), torch.Tensor(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b60c1c84-8267-4a3a-9e86-89363f8ec696",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 1000/1000 [04:57<00:00,  3.36it/s, loss=-15.9, epoch accu=0.667, test accu=0.667, num rules=50, sparsity=0.859] \n"
     ]
    }
   ],
   "source": [
    "# Train DR-Net\n",
    "# Default learning rate (1e-2), and_lam (1e-2), and and_lam (1e-5) usually work the best. A large epochs number is necessary for a sparse rule set i.e 10000 epochs.\n",
    "net = DRNet(train_set[:][0].size(1), 50, 1)\n",
    "train(net, train_set, test_set=test_set, device='cuda', lr=1e-2, epochs=1000, batch_size=5,\n",
    "      and_lam=1e-2, or_lam=1e-5, num_alter=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f208a470-759a-4499-a3a8-e4cf004c8663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6666666666666666, num rules: 50, num conditions: 352\n"
     ]
    }
   ],
   "source": [
    "# Get accuracy and the rule net\n",
    "accu = (net.predict(np.array(X_test)) == Y_test).mean()\n",
    "rules = net.get_rules(X_headers)\n",
    "print(f'Accuracy: {accu}, num rules: {len(rules)}, num conditions: {sum(map(len, rules))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7470ed52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique conditions: 12\n",
      "Average rule length: 7.04\n",
      "Number of rules: 50\n"
     ]
    }
   ],
   "source": [
    "average_rule_length = np.mean(([len(rule) for rule in rules]))\n",
    "unique_conditions = set()\n",
    "for rule in rules:\n",
    "    for condition in rule:\n",
    "        if isinstance(condition, tuple):\n",
    "            condition = condition[0]\n",
    "        unique_conditions.add(condition)\n",
    "\n",
    "compelxity_score = np.log(len(rules) + len(average_rule_length) + len(unique_conditions))\n",
    "print(f'Complexity score: {compelxity_score}')\n",
    "print(f'Number of unique conditions: {len(unique_conditions)}')    \n",
    "print(f'Average rule length: {average_rule_length}')\n",
    "print(f'Number of rules: {len(rules)}')\n",
    "\n",
    "res = pd.DataFrame(\n",
    "    {'Accuracy': [accu],\n",
    "     'Complexity score': [compelxity_score],\n",
    "     'Average rule length': [average_rule_length],\n",
    "     'Number of unique conditions': [len(unique_conditions)],\n",
    "     'Number of rules': [len(rules)]},\n",
    "    index=[name])\n",
    "res.to_csv('results_' + name + '.csv', sep=';')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datasci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
